
// Swap Method
    Queue<int> queue1;
    queue1.Init(K*L*sizeof(int));
    dev::Queue<int,uint32_t> d_queue1 = queue1.DeviceObject();

    Queue<int> queue2;
    queue2.Init(K*L* sizeof(int));
    dev::Queue<int,uint32_t> d_queue2 = queue2.DeviceObject();
    fetch_task<<<numBlocks,blockSize, 0, stream.cuda_stream()>>>(depth_d_view, d_queue1, 1);
    cudaDeviceSynchronize();
    fetch_task<<<numBlocks,blockSize, 0, stream.cuda_stream()>>>(depth_d_view, d_queue2, 0);
    cudaDeviceSynchronize();

    // Swap
    queue2.Swap(queue1);
    d_queue1 = queue1.DeviceObject();
    d_queue2 = queue2.DeviceObject();


    LaunchKernel(stream, [=]__device__() mutable {
//        d_queue2.Swap(d_queue1);
        for(int i=TID_1D;i<d_queue2.size();i+=TOTAL_THREADS_1D) {
            int k = d_queue2[i];
            printf("%u ", k);
        }
    });

// GPU Test
//__global__ void parallel_task(int* x_orl, int* x_kr, int* y_orl, int* y_kr, int* Delta, int* D, int* D_tree, int n, int m, int L, int* worklist1, int worklist1_tail){
//    int index = blockIdx.x * blockDim.x + threadIdx.x;
//    int stride = blockDim.x * gridDim.x;
//
//    for (int i=index; i<worklist1_tail; i+=stride){
//        task_GPU(x_orl,x_kr,y_orl,y_kr,Delta,D,D_tree,i,worklist1[i],L,m,n);
//        worklist1[i] = -1;
//    }
//}


    for (int x=0; x<num_batch; x++){
        int begin = min(x*batch_size,num_task);
        int end = min((x+1)*batch_size, num_task);
    }

    while (queue1.size() !=0 ) {
        parallel_task<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_x_kr_d, p_y_orl_d, p_y_kr_d, p_Delta_d, p_D_d, p_D_tree_d,
                                                n, m, L, d_queue1);
        stream.Sync();
        queue1.set_size(stream, 0);
        current_depth++;
        printf("Current depth is %u \n", current_depth);
        fetch_task<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(depth_d_view, d_queue1, current_depth);
        stream.Sync();
        printf("%zu \n", queue1.size());
    }


    int num_task = K*L;
    int num_batch = (num_task + batch_size - 1)/batch_size;
    int final_end = num_task % batch_size;

    for (int x=0; x<num_batch; x++){
        if (x != num_batch-1){
            parallel_task_stage<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_x_kr_d, p_y_orl_d, p_y_kr_d, p_Delta_d, p_D_d, p_D_tree_d,
                                                          n, m, L, d_queue1, batch_size, x, batch_size);
            stream.Sync();
        }else{
            parallel_task_stage<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_x_kr_d, p_y_orl_d, p_y_kr_d, p_Delta_d, p_D_d, p_D_tree_d,
                                                          n, m, L, d_queue1, batch_size, x, final_end);
            stream.Sync();
        }
    }


__global__ void parallel_task(int* x_orl, int* x_kr, int* y_orl, int* y_kr, int* Delta, int* D, int* D_tree, int n, int m, int L, dev::Queue<int, uint32_t> d_queue){
    for (int i=TID_1D; i<d_queue.size(); i+=TOTAL_THREADS_1D){
//        printf("%u ", d_queue[i]);
        task_GPU(x_orl,x_kr,y_orl,y_kr,Delta,D,D_tree,i,d_queue[i],L,m,n);
    }
}




//        if (queue1.size()==1){

//            single_table(stream, K*L-1, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);

//            int i = K*L-1;
//
//            int row = i / L;
//            int column = i % L;
//
//            int i_0;
//            int j_0;
//            int i_max;
//            int j_max;
//
//            i_0 = x_kr[row];
//            j_0 = y_kr[column];
//            i_max = x_orl[i_0] + 1;
//            j_max = y_orl[j_0] + 1;
//
//            int x = j_max - j_0 + 1;
//            int y = i_max - i_0 + 1;
//            int t;
//
//            cudaEvent_t start, stop;
//            cudaEventCreate(&start);
//            cudaEventCreate(&stop);
//            cudaEventRecord(start, stream.cuda_stream());
//
//            for (int k=1; k<=x+y-1; k++){
//                if(k<=x){
//                    t = min(k-1,i_max-i_0);
//                    numBlocks = (t + blockSize) / blockSize;
//                    parallel_single_table_1<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_y_orl_d, i_0, i_max, j_0, j_max, p_Delta_d, p_D_d, p_D_tree_d,
//                                                                                               n, m, t, k);
//                }else{
//                    t = min(j_max, i_max-i_0-k+x);
//                    numBlocks = (t + blockSize) / blockSize;
//                    parallel_single_table_2<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_y_orl_d, i_0, i_max, j_0, j_max, p_Delta_d, p_D_d, p_D_tree_d,
//                                                                                               n, m, t, k);
//                }
//            }
//            stream.Sync();
//
//            cudaEventRecord(stop, stream.cuda_stream());
//            cudaEventSynchronize(stop);
//            float milliseconds = 0;
//            cudaEventElapsedTime(&milliseconds, start, stop);
//            cudaEventDestroy(start);
//            cudaEventDestroy(stop);
//            printf("Measured time for parallel execution = %.3fms\n", milliseconds);

//            printf("Hello\n");

//        }else {}

////////////////////////////////////////////////////////////////////////////////////////////

    for (int i=0;i<queue1.size();i++) {
        for (int w = TID_1D; w <= t; w += TOTAL_THREADS_1D) {
            single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, i_max - w, j_max + 1 - k + w, Delta, D, D_tree,
                        i, m, n);
        }
    }

////////////////////////////////////////////////////////////////////////////////////////////

    for ( int gpu_id = 0; gpu_id < num_gpus; gpu_id++ ) {
        cudaSetDevice( gpu_id );
        int id;
        cudaGetDevice( &id );
        cudaMemGetInfo( &free, &total );
        cout << "GPU " << id << " memory: free=" << free << ", total=" << total << endl;
    }

////////////////////////////////////////////////////////////////////////////////////////////

__device__ void task_GPU_2(int* x_orl, int* x_kr, int* y_orl, int* y_kr, int* Delta, int* D, int* D_tree, int thread_in_number, int table_in_number, int L, int m, int n, int batch_size){
    int row = table_in_number / L;
    int column = table_in_number % L;
    int width = n+1;

    int i;
    int j;

    int i_0;
    int j_0;
    int i_max;
    int j_max;

    i_0 = x_kr[row];
    j_0 = y_kr[column];
    i_max = x_orl[i_0] + 1;
    j_max = y_orl[j_0] + 1;

    D[(i_max*width+j_max)*batch_size + thread_in_number]=0;

    for (i = i_max - 1; i > i_0 - 1; i--) {
        D[(i*width+j_max)*batch_size + thread_in_number] = 1 + D[((i+1)*width+j_max)*batch_size + thread_in_number];
    }

    for (j = j_max - 1; j > j_0 - 1; j--) {
        D[(i_max*width+j)*batch_size + thread_in_number] = 1 + D[(i_max*width+j+1)*batch_size + thread_in_number];
    }

    for (i = i_max - 1; i > i_0 - 1; i--) {
        for (j = j_max - 1; j > j_0 - 1; j--) {

            if ((x_orl[i] == x_orl[i_0]) & (y_orl[j] == y_orl[j_0])) {

                D[(i*width+j)*batch_size + thread_in_number] = min3_D(Delta[j+i*n]+D[((i+1)*width+j+1)*batch_size + thread_in_number],
                                                                      1+D[((i+1)*width+j)*batch_size + thread_in_number],
                                                                      1+D[(i*width+j+1)*batch_size + thread_in_number]);

                D_tree[j + i*n] = D[(i*width+j)*batch_size + thread_in_number];


            } else {
                D[(i*width+j)*batch_size + thread_in_number] = min3_D(D_tree[j + i*n]+D[((x_orl[i] + 1)*width+y_orl[j] + 1)*batch_size + thread_in_number],
                                                                      1+D[((i+1)*width+j)*batch_size + thread_in_number],
                                                                      1+D[(i*width+j+1)*batch_size + thread_in_number]);


            }
        }
    }
}

////////////////////////////////////////////////////////////////////////////////////////////


//            single_table(stream_array[0], queue_h[0], 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            cudaEventRecord(event[0], stream_array[0].cuda_stream());
//            single_table(stream_array[1], queue_h[1], 1, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            cudaEventRecord(event[1], stream_array[1].cuda_stream());
//            stream_array[1].Sync();
//            stream_array[2].Sync();
//            cudaStreamWaitEvent(stream.cuda_stream(),event[0]);
//            cudaStreamWaitEvent(stream.cuda_stream(),event[1]);

////////////////////////////////////////////////////////////////////////////////////////////
//        if (current_depth == 5){
//            printQueueVector<<<1, 1, 0, stream.cuda_stream()>>>(d_queue1);
//            stream.Sync();
//            printQueueVector<<<1, 1, 0, stream.cuda_stream()>>>(d_queue2);
//            stream.Sync();
//        }


////////////////////////////////////////////////////////////////////////////////////////////
//    vector<int> keys_h = {3, 1, 4, 1, 5, 9, 2, 6, 5};
//    vector<float> values_h = {0.1f, 0.2f, 0.3f, 0.4f, 0.5f, 0.6f, 0.7f, 0.8f, 0.9f};
//
//    thrust::device_vector<int> keys(keys_h);
//
//    // Create associated values
//    thrust::device_vector<float> values(values_h);
//
//    int *p_key = thrust::raw_pointer_cast(keys.data());
//    float *p_value = thrust::raw_pointer_cast(values.data());
//
//    std::cout << "world" << std::endl;

//    // Sort by keys
//    thrust::sort_by_key(keys.data(), keys.data()+keys.size(), values.data());

//    std::cout << "hello" << std::endl;
//
//    // Print the sorted keys and values
//    for (size_t i = 0; i < keys.size(); ++i)
//    {
//        std::cout << keys[i] << ": " << values[i] << std::endl;
//    }
////////////////////////////////////////////////////////////////////////////////////////////

__global__ void diagonal(int* matrix, int m, int n){

    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;
    int i,j;

    for (int step = 0; step<m+n-1; step++){
        i = x;
        j = step - x;
        if (y == j){
            printf("i = %u, j = %u, index=%u\n", i, j, x*n+y);
            matrix[x*n + y] = step;
        }
        __syncthreads();
    }
}

////////////////////////////////////////////////////////////////////////////////////////////

//__global__ void parallel_task(int* x_orl, int* x_kr, int* y_orl, int* y_kr, int* Delta, int* D, int* D_tree, int n, int m, int L, dev::Queue<int, uint32_t> d_queue){
//    for (int i=TID_1D; i<d_queue.size(); i+=TOTAL_THREADS_1D){
//        printf("%u ", d_queue[i]);
//        task_GPU(x_orl,x_kr,y_orl,y_kr,Delta,D,D_tree,i,d_queue[i],L,m,n);
//    }
//}

////////////////////////////////////////////////////////////////////////////////////////////

//            Stream stream1, stream2;
//            cudaEvent_t event1, event2;
//            cudaEventCreate(&event1);
//            cudaEventCreate(&event2);
//            multi_table_flag(0,stream1,d_queue1,queue1.size(),L,blockSize, n, m, p_x_orl_d, p_x_kr_d, p_y_orl_d, p_y_kr_d, p_Delta_d, p_D_d, p_D_tree_d);
//            multi_table_flag(1,stream2,d_queue1,queue1.size(),L,blockSize, n, m, p_x_orl_d, p_x_kr_d, p_y_orl_d, p_y_kr_d, p_Delta_d, p_D_d, p_D_tree_d);
//            cudaEventRecord(event1, stream1.cuda_stream());
//            cudaEventRecord(event2, stream2.cuda_stream());
//
//            stream1.Sync();
//            stream2.Sync();
//
//            cudaStreamWaitEvent(stream.cuda_stream(), event1);
//            cudaStreamWaitEvent(stream.cuda_stream(), event2);

////////////////////////////////////////////////////////////////////////////////////////////

void traverse(int node, vector<vector<int>>& a_adj) {
    // print the current node
    std::cout << node << " ";

    // traverse the child nodes recursively
    for (auto child : a_adj[node]) {
        traverse(child,a_adj);
    }
}

////////////////////////////////////////////////////////////////////////////////////////////

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i, index_j,
                            Delta, D, D_tree, 0, m, n);

                grid.sync();

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-1, index_j,
                            Delta, D, D_tree, 0, m, n);

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i, index_j-1,
                            Delta, D, D_tree, 0, m, n);

                grid.sync();

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-2, index_j,
                            Delta, D, D_tree, 0, m, n);

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-1, index_j-1,
                            Delta, D, D_tree, 0, m, n);

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i, index_j-2,
                            Delta, D, D_tree, 0, m, n);

                grid.sync();

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-3, index_j,
                            Delta, D, D_tree, 0, m, n);

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-2, index_j-1,
                            Delta, D, D_tree, 0, m, n);
                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-1, index_j-2,
                            Delta, D, D_tree, 0, m, n);
                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i, index_j-3,
                            Delta, D, D_tree, 0, m, n);
                grid.sync();

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-3, index_j-1,
                            Delta, D, D_tree, 0, m, n);

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-2, index_j-2,
                            Delta, D, D_tree, 0, m, n);

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-1, index_j-3,
                            Delta, D, D_tree, 0, m, n);

                grid.sync();

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-3, index_j-2,
                            Delta, D, D_tree, 0, m, n);

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-2, index_j-3,
                            Delta, D, D_tree, 0, m, n);

                grid.sync();

                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i-3, index_j-3,
                            Delta, D, D_tree, 0, m, n);

////////////////////////////////////////////////////////////////////////////////////////////
    row_size = (row_size + 1)/2;
    column_size = (column_size + 1)/2;
    int dayi = i_max/2;
    int yujie = j_max;
    void *kernel_args_1[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *)single_table_parallel_new, grid, block, kernel_args_1, 0, stream_sing.cuda_stream());

    dayi = i_max;
    yujie = j_max/2;
    void *kernel_args_2[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *)single_table_parallel_new, grid, block, kernel_args_2, 0, stream_sing.cuda_stream());

    dayi = i_max/2;
    yujie = j_max/2;
    void *kernel_args_3[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *)single_table_parallel_new, grid, block, kernel_args_3, 0, stream_sing.cuda_stream());

////////////////////////////////////////////////////////////////////////////////////////////

__global__ void single_table_parallel_new_test(int dayi, int yujie, int* x_orl, int* y_orl, int i_0, int i_max, int j_0, int j_max, int table_row_size, int table_column_size, int tile_size, int* Delta, int* D, int* D_tree, int n, int m){
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;

    __shared__ int row_size, column_size;

    row_size = (i_max-i_0+1 + tile_size - 1) / tile_size;
    column_size = (j_max-j_0+1 + tile_size - 1) / tile_size;


    row_size = (row_size + 1)/2;
    column_size = (column_size + 1)/2;

    for ( int i = x; i<row_size; i+=gridDim.x * blockDim.x){
        for ( int j=y; j<column_size; j+=gridDim.y * blockDim.y){

            for (int step = 0; step < row_size + column_size - 1; step++) {
                int index_i = (dayi - x * tile_size);
                int index_j = yujie - y * tile_size;
                for (int number = 0; number < 2 * tile_size - 1; number++) {
                    if (y == step - x) {
                        for (int j = max(0, number - tile_size + 1); j <= min(number, tile_size - 1); j++) {
                            single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i - number + j, index_j - j,
                                        Delta, D, D_tree, 0, m, n);
                        }
                    }
                    __syncthreads();
                }
            }
        }
    }
}

    tile = 16;
    grid = dim3(2,2);

//    single_table_parallel_new_test<<<grid, block,0,stream_sing.cuda_stream()>>>(i_max, j_max, p_x_orl_d, p_y_orl_d, i_0, i_max, j_0, j_max,m,n,tile, p_Delta_d, p_D_d, p_D_tree_d, n, m);

//    int dayi = i_max/2;
//    int yujie = j_max;
////    void *kernel_args_1[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
////    cudaLaunchCooperativeKernel((void *)single_table_parallel_new, grid, block, kernel_args_1, 0, stream_sing.cuda_stream());
//    single_table_parallel_new_test<<<grid, block,0,stream_sing.cuda_stream()>>>(dayi, yujie, p_x_orl_d, p_y_orl_d, i_0, i_max, j_0, j_max,m,n,tile, p_Delta_d, p_D_d, p_D_tree_d, n, m);
//
//    dayi = i_max;
//    yujie = j_max/2;
////    void *kernel_args_2[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
////    cudaLaunchCooperativeKernel((void *)single_table_parallel_new, grid, block, kernel_args_2, 0, stream_sing.cuda_stream());
//    single_table_parallel_new_test<<<grid, block,0,stream_sing.cuda_stream()>>>(dayi, yujie, p_x_orl_d, p_y_orl_d, i_0, i_max, j_0, j_max,m,n,tile, p_Delta_d, p_D_d, p_D_tree_d, n, m);
//
//    dayi = i_max/2;
//    yujie = j_max/2;
////    void *kernel_args_3[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
////    cudaLaunchCooperativeKernel((void *)single_table_parallel_new, grid, block, kernel_args_3, 0, stream_sing.cuda_stream());
//    single_table_parallel_new_test<<<grid, block,0,stream_sing.cuda_stream()>>>(dayi, yujie, p_x_orl_d, p_y_orl_d, i_0, i_max, j_0, j_max,m,n,tile, p_Delta_d, p_D_d, p_D_tree_d, n, m);

////////////////////////////////////////////////////////////////////////////////////////////

    grid = dim3 (8,8);
    tile = 2;

    printf("hello\n");

    void *kernel_args[] = {(void *)&i_max, (void *)&j_max, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *) single_table_parallel_new_test, grid, block, kernel_args, 0, stream_sing.cuda_stream());


    int dayi = i_max/2;
    int yujie = j_max;
    void *kernel_args_1[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *)single_table_parallel_new_test, grid, block, kernel_args_1, 0, stream_sing.cuda_stream());

    dayi = i_max;
    yujie = j_max/2;
    void *kernel_args_2[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *)single_table_parallel_new_test, grid, block, kernel_args_2, 0, stream_sing.cuda_stream());

    dayi = i_max/2;
    yujie = j_max/2;
    void *kernel_args_3[] = {(void *)&dayi, (void *)&yujie, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *)single_table_parallel_new_test, grid, block, kernel_args_3, 0, stream_sing.cuda_stream());

    __global__ void single_table_parallel_new_test(int dayi, int yujie, int* x_orl, int* y_orl, int i_0, int i_max, int j_0, int j_max, int table_row_size, int table_column_size, int tile_size, int* Delta, int* D, int* D_tree, int n, int m){
        int x = threadIdx.x + blockIdx.x * blockDim.x;
        int y = threadIdx.y + blockIdx.y * blockDim.y;

        __shared__ int row_size, column_size;

        row_size = (i_max-i_0+1 + tile_size - 1) / tile_size;
        column_size = (j_max-j_0+1 + tile_size - 1) / tile_size;


        row_size = (row_size + 1)/2;
        column_size = (column_size + 1)/2;

        cooperative_groups::grid_group grid = cooperative_groups::this_grid();

        for ( int i = x; i<row_size; i+=gridDim.x * blockDim.x){
            for ( int j=y; j<column_size; j+=gridDim.y * blockDim.y){

                for (int step = 0; step < row_size + column_size - 1; step++) {
                    int index_i = (dayi - x * tile_size);
                    int index_j = yujie - y * tile_size;
                    for (int number = 0; number < 2 * tile_size - 1; number++) {
                        if (y == step - x) {
                            for (int j = max(0, number - tile_size + 1); j <= min(number, tile_size - 1); j++) {
                                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i - number + j, index_j - j,
                                            Delta, D, D_tree, 0, m, n);
                            }
                        }
    //                    __syncthreads();
                    }
                    grid.sync();
                }
            }
        }
    }

////////////////////////////////////////////////////////////////////////////////////////////

//    Stream stream1;
//
//    const int N = 256;
//    const int block_size = 128;
//    const int grid_size = (N + block_size - 1) / block_size;
//
//    cudaEvent_t start, stop;
//    cudaEventCreate(&start);
//    cudaEventCreate(&stop);
//
//    cudaEventRecord(start, stream1.cuda_stream());
//
//    for (int i=0; i<=100000; i++){
//        test_time<<<grid_size, block_size, 0, stream1.cuda_stream()>>>();
//    }
//
//    cudaEventRecord(stop, stream1.cuda_stream());
//    cudaEventSynchronize(stop);
//    float milliseconds = 0;
//    cudaEventElapsedTime(&milliseconds, start, stop);
//    cudaEventDestroy(start);
//    cudaEventDestroy(stop);
//    printf("Measured time for parallel execution = %.3fms\n", milliseconds);

////////////////////////////////////////////////////////////////////////////////////////////

__device__ volatile int g_mutex;
__device__ void __gpu_sync(int goalVal)
{
    int tid_in_block = threadIdx.x * blockDim.y + threadIdx.y;  // Calculate the thread ID within the block

    if (tid_in_block == 0)  // Only thread 0 performs synchronization
    {
        atomicAdd((int*)&g_mutex, 1);  // Increment g_mutex using atomicAdd to avoid race conditions

        while (g_mutex != goalVal)  // Wait until g_mutex reaches the goal value
        {
            // Do nothing here, waiting for synchronization
        }
    }

    __syncthreads();  // Synchronize all threads in the block
}

__global__ void single_table_parallel_test_2(int* matrix, int m, int n){
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;
    int numBlocks = gridDim.x*gridDim.y;

    __gpu_sync(numBlocks);

}


__device__ void __gpu_sync_2(int goalVal, volatile int* Arrayin, volatile int* Arrayout)
{
    int tid_in_blk = threadIdx.x * blockDim.y + threadIdx.y;  // Calculate the thread ID within the block
    int nBlockNum = gridDim.x * gridDim.y;
    int bid = blockIdx.x * gridDim.y + blockIdx.y;  // Calculate the block ID

    if (tid_in_blk == 0)  // Only thread 0 performs synchronization
    {
        Arrayin[bid] = goalVal;  // Set the goal value in the input array
    }

    if (bid == 1)
    {
        if (tid_in_blk < nBlockNum)
        {
            while (Arrayin[tid_in_blk] != goalVal)  // Wait until all blocks have set the goal value
            {
                // Do nothing here, waiting for synchronization
            }
        }

        __syncthreads();

        if (tid_in_blk < nBlockNum)
        {
            Arrayout[tid_in_blk] = goalVal;  // Set the goal value in the output array
        }
    }

    if (tid_in_blk == 0)
    {
        while (Arrayout[bid] != goalVal)  // Wait until the current block has set the goal value
        {
            // Do nothing here, waiting for synchronization
        }
    }

    __syncthreads();  // Synchronize all threads in the block
}


__global__ void single_table_parallel_test_3(int* matrix, int m, int n){
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;
    int numBlocks = gridDim.x*gridDim.y;

    volatile int Array_in[numBlocks];
    volatile int Array_out[numBlocks];

    __gpu_sync_2(step+1, Array_in, Array_out);

}


////////////////////////////////////////////////////////////////////////////////////////////


__global__ void single_table_parallel_new_2(int thread_in_number, int* x_orl, int* y_orl, int i_0, int i_max, int j_0, int j_max, int table_row_size, int table_column_size, int tile_size, int* Delta, int* D, int* D_tree, int n, int m){
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;

    __shared__ int row_size, column_size;

    row_size = (i_max-i_0+1 + tile_size - 1) / tile_size;
    column_size = (j_max-j_0+1 + tile_size - 1) / tile_size;

    row_size = row_size/2+1;
    column_size = column_size/2+1;

    cooperative_groups::grid_group grid = cooperative_groups::this_grid();


    for ( int i = x; i<row_size; i+=gridDim.x * blockDim.x){
        for ( int j=y; j<column_size; j+=gridDim.y * blockDim.y){

            for (int step = 0; step < row_size + column_size - 1; step++) {
                for (int number = 0; number < 2 * tile_size - 1; number++) {
                    if (y == step - x) {
                        int index_i = (i_max - x * tile_size);
                        int index_j = j_max - y * tile_size;
                        for (int j = max(0, number - tile_size + 1); j <= min(number, tile_size - 1); j++) {
                            single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i - number + j, index_j - j,
                                        Delta, D, D_tree, thread_in_number, m, n);
                        }
                    }
                }
                grid.sync();
            }

            for (int step = 0; step < row_size + column_size - 1; step++) {
                for (int number = 0; number < 2 * tile_size - 1; number++) {
                    if (y == step - x) {
                        int index_i = (i_max/2 - x * tile_size);
                        int index_j = j_max - y * tile_size;
                        for (int j = max(0, number - tile_size + 1); j <= min(number, tile_size - 1); j++) {
                            single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i - number + j, index_j - j,
                                        Delta, D, D_tree, thread_in_number, m, n);
                        }
                    }
                }
                grid.sync();
            }

            for (int step = 0; step < row_size + column_size - 1; step++) {
                for (int number = 0; number < 2 * tile_size - 1; number++) {
                    if (y == step - x) {
                        int index_i = (i_max - x * tile_size);
                        int index_j = j_max/2 - y * tile_size;
                        for (int j = max(0, number - tile_size + 1); j <= min(number, tile_size - 1); j++) {
                            single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i - number + j, index_j - j,
                                        Delta, D, D_tree, thread_in_number, m, n);
                        }
                    }
                }
                grid.sync();
            }

            for (int step = 0; step < row_size + column_size - 1; step++) {
                for (int number = 0; number < 2 * tile_size - 1; number++) {
                    if (y == step - x) {
                        int index_i = (i_max/2 - x * tile_size);
                        int index_j = j_max/2 - y * tile_size;
                        for (int j = max(0, number - tile_size + 1); j <= min(number, tile_size - 1); j++) {
                            single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, index_i - number + j, index_j - j,
                                        Delta, D, D_tree, thread_in_number, m, n);
                        }
                    }
                }
                grid.sync();
            }

        }
    }
}


void single_table_new_2(Stream& stream_sing, int i, int thread_in_number, vector<int>& x_orl, vector<int>& x_kr, vector<int>& y_orl, vector<int>& y_kr, int L, int blockSize, int n, int m, int *p_x_orl_d, int *p_y_orl_d, int *p_Delta_d, int *p_D_d, int *p_D_tree_d){
    int row = i / L;
    int column = i % L;

    int i_0 = x_kr[row];
    int j_0 = y_kr[column];
    int i_max = x_orl[i_0] + 1;
    int j_max = y_orl[j_0] + 1;
    int tile = 4;

    dim3 block(32,32);
    dim3 grid((m+tile*block.x)/(tile*block.x),(n+tile*block.y)/(tile*block.y));

    printf("New2 %u, %u, %u, %u\n", block.x, block.y, grid.x, grid.y);
    grid = dim3(4,4);

    void *kernel_args[] = { (void*)&thread_in_number, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *) single_table_parallel_new_2, grid, block, kernel_args, 0, stream_sing.cuda_stream());

//    CHECK_CUDA(cudaDeviceSynchronize());
//    cudaError_t error = cudaGetLastError();
//    if(error != cudaSuccess)
//    {
//        // print the CUDA error message and exit
//        printf("CUDA error: %s\n", cudaGetErrorString(error));
//        exit(-1);
//    }
}


////////////////////////////////////////////////////////////////////////////////////////////



__global__ void single_table_parallel_new_3(int thread_in_number, int* x_orl, int* y_orl, int i_0, int i_max, int j_0, int j_max, int table_row_size, int table_column_size, int tile_size, int* Delta, int* D, int* D_tree, int n, int m){
    int x = threadIdx.x + blockIdx.x * blockDim.x;

//    __shared__ int row_size, column_size;

    int row_size = (i_max-i_0+1 + tile_size - 1) / tile_size;
    int column_size = (j_max-j_0+1 + tile_size - 1) / tile_size;

    int column_thread = blockDim.x*gridDim.x;

    row_size = m+1;
    column_size = n+1;


    cooperative_groups::grid_group grid = cooperative_groups::this_grid();


    for (int step = 0; step<row_size+column_size-1;step++) {
        for (int j = max(0,step-column_size+1); j<=min(step, row_size-1); j++){
            if (j%column_thread == x){
                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, row_size-1-j, column_size-1-step+j,
                            Delta, D, D_tree, thread_in_number, m, n);
            }
        }
        __syncthreads();
//        grid.sync();
    }


}


void single_table_new_3(Stream& stream_sing, int i, int thread_in_number, vector<int>& x_orl, vector<int>& x_kr, vector<int>& y_orl, vector<int>& y_kr, int L, int blockSize, int n, int m, int *p_x_orl_d, int *p_y_orl_d, int *p_Delta_d, int *p_D_d, int *p_D_tree_d){
    int row = i / L;
    int column = i % L;

    int i_0 = x_kr[row];
    int j_0 = y_kr[column];
    int i_max = x_orl[i_0] + 1;
    int j_max = y_orl[j_0] + 1;
    int tile = 1;

//    dim3 block(32,32);
//    dim3 grid((m+tile*block.x)/(tile*block.x),(n+tile*block.y)/(tile*block.y));

    int one_block = 1024;
    int one_grid = 4;

//    printf("test8\n");
    void *kernel_args[] = { (void*)&thread_in_number, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *) single_table_parallel_new_3, one_grid, one_block, kernel_args, 0, stream_sing.cuda_stream());

//    CHECK_CUDA(cudaDeviceSynchronize());
//    cudaError_t error = cudaGetLastError();
//    if(error != cudaSuccess)
//    {
//        // print the CUDA error message and exit
//        printf("CUDA error: %s\n", cudaGetErrorString(error));
//        exit(-1);
//    }
}


////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

__global__ void single_table_parallel_new_4(int thread_in_number, int* x_orl, int* y_orl, int i_0, int i_max, int j_0, int j_max, int table_row_size, int table_column_size, int tile_size, int* Delta, int* D, int* D_tree, int n, int m){
    int x = threadIdx.x + blockIdx.x * blockDim.x;
    int y = threadIdx.y + blockIdx.y * blockDim.y;

    int row_thread = gridDim.x * blockDim.x;
    int column_thread = gridDim.y * blockDim.y;

    __shared__ int row_size, column_size;

    row_size = (i_max-i_0+1 + tile_size - 1) / tile_size;
    column_size = (j_max-j_0+1 + tile_size - 1) / tile_size;

//    row_size = row_size / 2;
//    column_size = column_size / 2;


    cooperative_groups::grid_group grid = cooperative_groups::this_grid();


    for (int step = 0; step<row_size+column_size-1;step++) {
        for (int j = max(0,step-column_size+1); j<=min(step, row_size-1); j++){
            if (j%row_thread == x & (step-j)%column_thread == y){
                single_unit(x_orl, y_orl, i_0, i_max, j_0, j_max, row_size-1-j, column_size-1-step+j,
                            Delta, D, D_tree, thread_in_number, m, n);
//                int c = 1+1;
            }
        }
//        __syncthreads();
        grid.sync();
    }


}


void single_table_new_4(Stream& stream_sing, int i, int thread_in_number, vector<int>& x_orl, vector<int>& x_kr, vector<int>& y_orl, vector<int>& y_kr, int L, int blockSize, int n, int m, int *p_x_orl_d, int *p_y_orl_d, int *p_Delta_d, int *p_D_d, int *p_D_tree_d){
    int row = i / L;
    int column = i % L;

    int i_0 = x_kr[row];
    int j_0 = y_kr[column];
    int i_max = x_orl[i_0] + 1;
    int j_max = y_orl[j_0] + 1;
    int tile = 1;

    dim3 block(32,32);
    dim3 grid(4,4);
//    dim3 grid((m+tile*block.x)/(tile*block.x),(n+tile*block.y)/(tile*block.y));


    printf("test6\n");
    printf("hello\n");
    void *kernel_args[] = { (void*)&thread_in_number, (void*)&p_x_orl_d, (void*)&p_y_orl_d,  (void *)&i_0, (void *)&i_max, (void *)&j_0, (void *)&j_max, (void *)&m, (void *)&n, (void *)&tile, (void *)&p_Delta_d, (void *)&p_D_d, (void *)&p_D_tree_d, (void *)&n, (void *)&m};
    cudaLaunchCooperativeKernel((void *) single_table_parallel_new_4, grid, block, kernel_args, 0, stream_sing.cuda_stream());

//    single_table_parallel_new_4<<<grid, block, 0, stream_sing.cuda_stream()>>>(thread_in_number, p_x_orl_d, p_y_orl_d, i_0, i_max, j_0, j_max, m, n, tile, p_Delta_d, p_D_d, p_D_tree_d, n, m);

    CHECK_CUDA(cudaDeviceSynchronize());
    cudaError_t error = cudaGetLastError();
    if(error != cudaSuccess)
    {
        // print the CUDA error message and exit
        printf("CUDA error: %s\n", cudaGetErrorString(error));
        exit(-1);
    }
}


////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

        int i_max = p_i_max[1];
        int j_max = p_j_max[1];
        int i_0 = p_i_0[1];
        int j_0 = p_j_0[1];

        int f = blockIdx.x;
        int x_loc = i_max - 5*(f-32);
        int y_loc = j_max - threadIdx.x;

        int w=0;
        for (int step = 0; step < i_max+j_max-i_0-j_0+1; step++) {
            if(((x_loc + y_loc) == (i_max+j_max - step)) && (w<5) && y_loc>=j_0 && x_loc>=i_0 ){

                single_unit_10(x_orl, y_orl, i_0, i_max, j_0, j_max, x_loc, y_loc,
                               Delta, D, D_tree, 1, m, n);

                x_loc--;
                w++;
            }
            __gpu_sync_range(32,63,step,Array_in,Array_out);
        }


                int i_max = p_i_max[1];
                int j_max = p_j_max[1];
                int i_0 = p_i_0[1];
                int j_0 = p_j_0[1];

                int x_loc = i_max - threadIdx.x;
                int y_loc = j_max - 32*(blockIdx.x-32);


                int w=0;
                for (int step = 0; step < i_max+j_max-i_0-j_0+1; step++) {
                    if(((x_loc + y_loc) == (i_max+j_max - step)) && (w<32) && y_loc>=j_0 && x_loc>=i_0 ){

                        single_unit_10(x_orl, y_orl, i_0, i_max, j_0, j_max, x_loc, y_loc,
                                       Delta, D, D_tree, 1, m, n);

                        y_loc--;
                        w++;
                    }
                    __gpu_sync_range(32,63,step,Array_in,Array_out);
                }


////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//            thrust::host_vector<int> queue_h(queue1.size());
//            cudaMemcpyAsync(thrust::raw_pointer_cast(queue_h.data()),
//                            queue1.data(), queue1.size() * sizeof(int),
//                            cudaMemcpyDeviceToHost, stream.cuda_stream());
//            stream.Sync();
//
//
//            Stream stream_array[5];
//            cudaEvent_t event[5];
//            cudaEvent_t start, stop;
//            cudaEventCreate(&start);
//            cudaEventCreate(&stop);
//
//            for(int i=0; i<5; i++) {
//                cudaEventCreate(&event[i]);
//            }
//
//            cudaEventRecord(start, stream.cuda_stream());
//
//
//            for (int i=0; i < queue_h.size(); i++){
//                if(i==0){
//                    single_table(stream_array[i], queue_h[i], 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//                }
//                if(i==1){
//                    single_table(stream_array[i], queue_h[i], 1, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//                }
//                cudaEventRecord(event[i], stream_array[i].cuda_stream());
////                stream_array[i].Sync();
//            }
//
//            for (int i=0; i< queue_h.size();i++){
//                cudaStreamWaitEvent(stream.cuda_stream(),event[i],0);
//            }
//
//
//            cudaEventRecord(stop, stream.cuda_stream());
//            cudaEventSynchronize(stop);
//            float milliseconds = 0;
//            cudaEventElapsedTime(&milliseconds, start, stop);
//            cudaEventDestroy(start);
//            cudaEventDestroy(stop);
//            printf("Measured time for parallel execution = %.3fms\n", milliseconds);
//            total_milliseconds+=milliseconds;
//
//            for(int i=0; i<5; i++) {
//                cudaEventDestroy(event[i]);
//            }

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//            cudaEvent_t start, stop;
//            float milliseconds = 0;
//            cudaEventCreate(&start);
//            cudaEventCreate(&stop);
//            cudaEventRecord(start, stream.cuda_stream());
//
//            multi_table(stream,d_queue1,queue1.size(),L,blockSize, n, m, p_x_orl_d, p_x_kr_d, p_y_orl_d, p_y_kr_d, p_Delta_d, p_D_d, p_D_tree_d);
//
//            cudaEventRecord(stop, stream.cuda_stream());
//            cudaEventSynchronize(stop);
//            cudaEventElapsedTime(&milliseconds, start, stop);
//            cudaEventDestroy(start);
//            cudaEventDestroy(stop);
//            printf("Measured time for hell0 parallel execution = %.3fms\n", milliseconds);
//            total_milliseconds+=milliseconds;
//            thrust::host_vector<int> queue_h(queue1.size());
//            cudaMemcpyAsync(thrust::raw_pointer_cast(queue_h.data()),
//                            queue1.data(), queue1.size() * sizeof(int),
//                            cudaMemcpyDeviceToHost, stream.cuda_stream());
//            stream.Sync();
//
//            multi_table_new_update(stream, queue_h, x_orl, x_kr, y_orl, y_kr, d_queue1, queue_h.size(), L, n, m, p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//            single_table(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            single_table_new(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            single_table_new_3(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            single_table_new_2(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            single_table_new_4(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            single_table_new_5(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            single_table_new_6(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            single_table_new_7(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//            single_table_new_8(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

第一阶段并行 -- Batch 版本



//    auto start_time = chrono::steady_clock::now();
    while (queue1.size() !=0 ) {

        printf("\ncurrent depth = %d\n", current_depth);


        if (queue1.size() <= 256 && queue1.size()>5){

            thrust::host_vector<int> queue_h(queue1.size());
            cudaMemcpyAsync(thrust::raw_pointer_cast(queue_h.data()),
                            queue1.data(), queue1.size() * sizeof(int),
                            cudaMemcpyDeviceToHost, stream.cuda_stream());
            stream.Sync();

            multi_table_new_update_8(stream, total_milliseconds, queue_h, x_orl, x_kr, y_orl, y_kr, d_queue1, queue_h.size(), L, n, m, p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);



        }else if (queue1.size()<=5 && queue1.size()>1){

            thrust::host_vector<int> queue_h(queue1.size());
            cudaMemcpyAsync(thrust::raw_pointer_cast(queue_h.data()),
                            queue1.data(), queue1.size() * sizeof(int),
                            cudaMemcpyDeviceToHost, stream.cuda_stream());
            stream.Sync();


//            multi_table_new(stream, queue_h, x_orl, x_kr, y_orl, y_kr, d_queue1, queue_h.size(), L, n, m, p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
            multi_table_new_update_8(stream, total_milliseconds, queue_h, x_orl, x_kr, y_orl, y_kr, d_queue1, queue_h.size(), L, n, m, p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
//



        }else if (queue1.size()==1){

            cudaEvent_t start, stop;
            float milliseconds = 0;
            cudaEventCreate(&start);
            cudaEventCreate(&stop);
            cudaEventRecord(start, stream.cuda_stream());


            single_table_new_9(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
            cudaEventRecord(stop, stream.cuda_stream());
            cudaEventSynchronize(stop);
            cudaEventElapsedTime(&milliseconds, start, stop);
            cudaEventDestroy(start);
            cudaEventDestroy(stop);
            printf("Measured time for parallel execution = %.3fms\n", milliseconds);
            total_milliseconds+=milliseconds;


        }else{
            cudaEvent_t start, stop;
            cudaEventCreate(&start);
            cudaEventCreate(&stop);

            int num_task = queue1.size();
            int num_batch = (num_task + batch_size - 1) / (batch_size);
            int final_end = num_task % batch_size;
            if (final_end == 0) { final_end = batch_size; }

            printf("numTasks = %d, numBatchs  = %d\n", num_task, num_batch);

//            Stream stream_large;
//            cudaEvent_t event_large;
//            cudaEventCreate(&event_large);
//
//            thrust::host_vector<int> large_queue_h(large_queue.size());
//            cudaMemcpyAsync(thrust::raw_pointer_cast(large_queue_h.data()),
//                            large_queue.data(), large_queue.size() * sizeof(int),
//                            cudaMemcpyDeviceToHost, stream_large.cuda_stream());
//            stream_large.Sync();

            cudaEventRecord(start, stream.cuda_stream());


            numBlocks = (num_task + blockSize - 1) / blockSize;

            numBlocks = 128;

            printf("numBlocks = %d\n", numBlocks);


            simple_parallel<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_x_kr_d,
                                                                                           p_y_orl_d, p_y_kr_d,
                                                                                           p_Delta_d, p_D_d, p_D_d_2, p_D_tree_d,
                                                                                           n, m, L, d_queue1);


//            for (int x = 0; x < num_batch; x++) {
//                if (x != num_batch - 1) {
//                    numBlocks = (batch_size + blockSize - 1) / blockSize;
//                    printf("begin = %d, end = %d\n", 0, batch_size);
//                    parallel_task_stage<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_x_kr_d,
//                                                                                           p_y_orl_d, p_y_kr_d,
//                                                                                           p_Delta_d, p_D_d, p_D_d_2, p_D_tree_d,
//                                                                                           n, m, L, d_queue1,
//                                                                                           batch_size, x, batch_size);
//                } else {
//                    numBlocks = (final_end + blockSize - 1) / blockSize;
//                    printf("begin = %d, end = %d\n", 0, final_end);
//                    parallel_task_stage<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_x_kr_d,
//                                                                                           p_y_orl_d, p_y_kr_d,
//                                                                                           p_Delta_d, p_D_d, p_D_d_2, p_D_tree_d,
//                                                                                           n, m, L, d_queue1,
//                                                                                           batch_size, x, final_end);
//                }
//            }


//            if (large_queue.size() != 0){
//                for (int i=0; i< large_queue.size(); i++){
//                    single_table(stream_large, large_queue_h[i], i, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d_2, p_D_tree_d);
//                }
//                cudaEventRecord(event_large, stream_large.cuda_stream());
//            }
//
//
//            cudaStreamWaitEvent(stream.cuda_stream(),event_large,0);


            cudaEventRecord(stop, stream.cuda_stream());
            cudaEventSynchronize(stop);
            float milliseconds = 0;
            cudaEventElapsedTime(&milliseconds, start, stop);
            cudaEventDestroy(start);
            cudaEventDestroy(stop);
            printf("Measured time for parallel execution = %.3fms\n", milliseconds);
            total_milliseconds+=milliseconds;
        }

        queue1.set_size(stream, 0);
        large_queue.set_size(stream, 0);
        current_depth++;
        numBlocks = (depth_d_view.size() + blockSize - 1) / blockSize;
        fetch_task<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(depth_d_view, d_queue1, current_depth);
        stream.Sync();

        // Sort by Size
        queue2.set_size(stream, queue1.size());
        numBlocks = (queue1.size() + blockSize - 1) / blockSize;

        fetch_size_queue<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(d_queue2, d_queue1,p_x_orl_d, p_y_orl_d, p_x_kr_d, p_y_kr_d, L);
        stream.Sync();

        thrust::sort_by_key(queue2.getRawPointer(), queue2.getRawPointer()+queue1.size(), queue1.getRawPointer());
        cudaStreamSynchronize(stream.cuda_stream());
        queue2.set_size(stream,0);

        if(current_depth <= -5 && current_depth >-1) {
//            printQueueVector<<<1, 1, 0, stream.cuda_stream()>>>(d_queue1);
            numBlocks = (queue1.size() + blockSize - 1) / blockSize;
            filter<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(d_queue1, d_queue2, d_large_queue, 125125);
            stream.Sync();
            int old_size = queue1.size();
            queue1.set_size(stream,old_size - large_queue.size());
        }
    }

    ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


    //vector<vector<int>> parallel_standard_ted_2_18(vector<int>& x_orl, vector<int>& x_kr, vector<int>& y_orl, vector<int>& y_kr, vector<vector<int>>& Delta, vector<vector<int>>& D, vector<vector<int>>& D_tree, int m, int n, int num_threads, vector<vector<int>>& x_adj, vector<vector<int>>& y_adj){
    //
    //    int K = (int)x_kr.size();
    //    int L = (int)y_kr.size();
    //
    //
    //    vector<int> depth(K*L, 0);
    //
    //    int number_x_nodes = x_adj.size();
    //    int number_y_nodes = y_adj.size();
    //
    //
    //    vector<int> x_keyroot_depth_2(K, 0);
    //    vector<int> y_keyroot_depth_2(L, 0);
    //
    //// Preprocessing
    //
    //    for (int i=0;i<K;i++){
    //        int node = x_kr[i];
    //        if((node == x_orl[node])||(node == x_orl[node]-1)){
    //            x_keyroot_depth_2[i] = 0;
    //        }else{
    //            for (int j=0;j<i;j++){
    //                int node_2 = x_kr[j];
    //                if ((node <= node_2)&&(x_orl[node] >= node_2)){
    //                    x_keyroot_depth_2[i] = max(x_keyroot_depth_2[i],x_keyroot_depth_2[j]+1);
    //                }
    //            }
    //        }
    //    }
    //
    //    for (int i=0;i<L;i++){
    //        int node = y_kr[i];
    //        if((node == y_orl[node])||(node == y_orl[node]-1)){
    //            y_keyroot_depth_2[i] = 0;
    //        }else{
    //            for (int j=0;j<i;j++){
    //                int node_2 = y_kr[j];
    //                if ((node <= node_2)&&(y_orl[node] >= node_2)){
    //                    y_keyroot_depth_2[i] = max(y_keyroot_depth_2[i],y_keyroot_depth_2[j]+1);
    //                }
    //            }
    //        }
    //    }
    //
    //    for (int i=0;i<K*L;i++){
    //        depth[i] = x_keyroot_depth_2[i/L] + y_keyroot_depth_2[i%L];
    //    }
    //
    //
    //    // GPU Programming
    //    int blockSize = 256;
    //    int current_depth = 0;
    //    double limitation = (8*1024*1024*1024.0)/((m+1)*(n+1)*4);
    //    printf("limitation is %u\n", int(limitation));
    //    int batch_size = min(K*L,int(limitation));
    //
    //    // x_orl, x_kr, y_orl, y_kr
    //    thrust::device_vector<int> x_orl_d(x_orl);
    //    thrust::device_vector<int> x_kr_d(x_kr);
    //    thrust::device_vector<int> y_orl_d(y_orl);
    //    thrust::device_vector<int> y_kr_d(y_kr);
    //
    //    // Delta, D_tree
    //    vector<int> Delta_trans (m*n);
    //    for (int i=0; i<m;i++){
    //        for (int j=0; j<n;j++){
    //            Delta_trans[i*n+j] = Delta[i][j];
    //        }
    //    }
    //    thrust::device_vector<int> Delta_d(Delta_trans);
    //    vector<int> D_tree_trans(m*n, 0);
    //    thrust::device_vector<int> D_tree_d(D_tree_trans);
    //
    //    // depth
    //    thrust::device_vector<int> depth_d(depth);
    //
    //    // D
    ////    vector<int> D_trans((m+1)*(n+1)*batch_size, 0);
    ////    thrust::device_vector<int> D_d(D_trans);
    //    thrust::device_vector<int> D_d((m+1)*(n+1)*batch_size, 0);
    ////    thrust::device_vector<int> D_d_2((m+1)*(n+1)*batch_size, 0);
    //
    //    // Size
    ////    vector<int> size(K*L,0);
    ////    thrust::device_vector<int> size_d(size);
    //
    //    // Pointer: x_orl, x_kr, y_orl, y_kr, Delta, D_tree, depth, worklist1, worklist2, D
    //    int *p_x_orl_d = thrust::raw_pointer_cast(x_orl_d.data());
    //    int *p_x_kr_d = thrust::raw_pointer_cast(x_kr_d.data());
    //    int *p_y_orl_d = thrust::raw_pointer_cast(y_orl_d.data());
    //    int *p_y_kr_d = thrust::raw_pointer_cast(y_kr_d.data());
    //    int *p_Delta_d = thrust::raw_pointer_cast(Delta_d.data());
    //    int *p_D_tree_d = thrust::raw_pointer_cast(D_tree_d.data());
    //    int *p_depth_d = thrust::raw_pointer_cast(depth_d.data());
    //    int *p_D_d = thrust::raw_pointer_cast(D_d.data());
    ////    int *p_D_d_2 = thrust::raw_pointer_cast(D_d_2.data());
    //
    //    float total_milliseconds = 0;
    //
    //    Stream stream;
    //
    //    ArrayView<int> depth_d_view(depth_d);
    //
    //    Queue<int> queue1;
    //    queue1.Init(K*L*sizeof(int));
    //    dev::Queue<int,uint32_t> d_queue1 = queue1.DeviceObject();
    //
    //    Queue<int> queue2;
    //    queue2.Init(K*L*sizeof(int));
    //    dev::Queue<int,uint32_t> d_queue2 = queue2.DeviceObject();
    //
    //    Queue<int> large_queue;
    //    large_queue.Init(K*L*sizeof(int));
    //    dev::Queue<int,uint32_t> d_large_queue = large_queue.DeviceObject();
    //    large_queue.set_size(stream, 0);
    //
    //
    //    // Fetch task
    //
    //    int numBlocks = (int)(depth_d_view.size() + blockSize - 1) / blockSize;
    //    fetch_task<<<numBlocks,blockSize, 0, stream.cuda_stream()>>>(depth_d_view, d_queue1, 0);
    //    stream.Sync();
    //
    //    initializeArrayToZero<<<1, 64>>>();
    //    CHECK_CUDA(cudaDeviceSynchronize());
    //    cudaError_t error = cudaGetLastError();
    //    if(error != cudaSuccess)
    //    {
    //        // print the CUDA error message and exit
    //        printf("CUDA error: %s\n", cudaGetErrorString(error));
    //        exit(-1);
    //    }
    //
    ////    batch_size = batch_size*2;
    //
    ////    auto start_time = chrono::steady_clock::now();
    //    while (queue1.size() !=0 ) {
    //
    //        printf("\ncurrent depth = %d, batch_size = %d\n", current_depth, batch_size);
    //
    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    //
    //        if (queue1.size() <= 256 && queue1.size()>5){
    //
    //            thrust::host_vector<int> queue_h(queue1.size());
    //            cudaMemcpyAsync(thrust::raw_pointer_cast(queue_h.data()),
    //                            queue1.data(), queue1.size() * sizeof(int),
    //                            cudaMemcpyDeviceToHost, stream.cuda_stream());
    //            stream.Sync();
    //
    //            multi_table_new_update_8(stream, total_milliseconds, queue_h, x_orl, x_kr, y_orl, y_kr, d_queue1, queue_h.size(), L, n, m, p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
    //
    //
    //
    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    //
    //        }else if (queue1.size()<=5 && queue1.size()>1){
    //
    //            thrust::host_vector<int> queue_h(queue1.size());
    //            cudaMemcpyAsync(thrust::raw_pointer_cast(queue_h.data()),
    //                            queue1.data(), queue1.size() * sizeof(int),
    //                            cudaMemcpyDeviceToHost, stream.cuda_stream());
    //            stream.Sync();
    //
    //
    ////            multi_table_new(stream, queue_h, x_orl, x_kr, y_orl, y_kr, d_queue1, queue_h.size(), L, n, m, p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
    //            multi_table_new_update_8(stream, total_milliseconds, queue_h, x_orl, x_kr, y_orl, y_kr, d_queue1, queue_h.size(), L, n, m, p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
    ////
    //
    //
    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    //
    //        }else if (queue1.size()==1){
    //
    //            cudaEvent_t start, stop;
    //            float milliseconds = 0;
    //            cudaEventCreate(&start);
    //            cudaEventCreate(&stop);
    //            cudaEventRecord(start, stream.cuda_stream());
    //
    //
    //            single_table_new_9(stream, K*L-1, 0, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d, p_D_tree_d);
    //            cudaEventRecord(stop, stream.cuda_stream());
    //            cudaEventSynchronize(stop);
    //            cudaEventElapsedTime(&milliseconds, start, stop);
    //            cudaEventDestroy(start);
    //            cudaEventDestroy(stop);
    //            printf("Measured time for parallel execution = %.3fms\n", milliseconds);
    //            total_milliseconds+=milliseconds;
    //
    //
    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    //
    //        }else{
    //            cudaEvent_t start, stop;
    //            cudaEventCreate(&start);
    //            cudaEventCreate(&stop);
    //
    //
    ////            Stream stream_large;
    ////            cudaEvent_t event_large;
    ////            cudaEventCreate(&event_large);
    ////
    ////            thrust::host_vector<int> large_queue_h(large_queue.size());
    ////            cudaMemcpyAsync(thrust::raw_pointer_cast(large_queue_h.data()),
    ////                            large_queue.data(), large_queue.size() * sizeof(int),
    ////                            cudaMemcpyDeviceToHost, stream_large.cuda_stream());
    ////            stream_large.Sync();
    //
    //
    //            int num_task = queue1.size();
    //            numBlocks = (num_task + blockSize - 1) / blockSize;
    //            numBlocks = 128;
    //            printf("numBlocks = %d，Hello 2 numTasks = %d\n", numBlocks,num_task);
    //
    //            cudaEventRecord(start, stream.cuda_stream());
    ////            simple_parallel<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_x_kr_d, p_y_orl_d, p_y_kr_d, p_Delta_d, p_D_d, p_D_d_2, p_D_tree_d, n, m, L, d_queue1,batch_size);
    //            simple_parallel_new<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(p_x_orl_d, p_x_kr_d, p_y_orl_d, p_y_kr_d, p_Delta_d, p_D_d, p_D_tree_d, n, m, L, d_queue1,batch_size);
    //
    //
    ////            if (large_queue.size() != 0){
    ////                for (int i=0; i< large_queue.size(); i++){
    ////                    single_table(stream_large, large_queue_h[i], i, x_orl, x_kr, y_orl, y_kr, L, blockSize, n, m , p_x_orl_d, p_y_orl_d, p_Delta_d, p_D_d_2, p_D_tree_d);
    ////                }
    ////                cudaEventRecord(event_large, stream_large.cuda_stream());
    ////            }
    ////
    ////
    ////            cudaStreamWaitEvent(stream.cuda_stream(),event_large,0);
    //
    //
    //            cudaEventRecord(stop, stream.cuda_stream());
    //            cudaEventSynchronize(stop);
    //            float milliseconds = 0;
    //            cudaEventElapsedTime(&milliseconds, start, stop);
    //            cudaEventDestroy(start);
    //            cudaEventDestroy(stop);
    //            printf("Measured time for parallel execution = %.3fms\n", milliseconds);
    //            total_milliseconds+=milliseconds;
    //        }
    //
    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    //        queue1.set_size(stream, 0);
    //        large_queue.set_size(stream, 0);
    //        current_depth++;
    //        numBlocks = (depth_d_view.size() + blockSize - 1) / blockSize;
    //        fetch_task<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(depth_d_view, d_queue1, current_depth);
    //        stream.Sync();
    //
    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    //
    //        // Sort by Size
    //        queue2.set_size(stream, queue1.size());
    //        numBlocks = (queue1.size() + blockSize - 1) / blockSize;
    //
    //        fetch_size_queue<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(d_queue2, d_queue1,p_x_orl_d, p_y_orl_d, p_x_kr_d, p_y_kr_d, L);
    //        stream.Sync();
    //
    //        thrust::sort_by_key(queue2.getRawPointer(), queue2.getRawPointer()+queue1.size(), queue1.getRawPointer());
    //        cudaStreamSynchronize(stream.cuda_stream());
    //        queue2.set_size(stream,0);
    //
    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    //
    //        if(current_depth <= -5 && current_depth >1) {
    ////            printQueueVector<<<1, 1, 0, stream.cuda_stream()>>>(d_queue1);
    //            numBlocks = (queue1.size() + blockSize - 1) / blockSize;
    //            filter<<<numBlocks, blockSize, 0, stream.cuda_stream()>>>(d_queue1, d_queue2, d_large_queue, 125125);
    //            stream.Sync();
    //            int old_size = queue1.size();
    //            queue1.set_size(stream,old_size - large_queue.size());
    //        }
    //    }
    //
    ////    auto end_time = chrono::steady_clock::now();
    ////    auto ms = chrono::duration_cast<chrono::microseconds>(end_time - start_time).count();
    ////    cout << "Parallel-GPU Concurrent task finish, " << ms/1000.0 << " ms consumed" << endl;
    //
    //
    //    int final = D_tree_d[0];
    //    printf("The total final distance is %u\n", final);
    //    printf("hello\n");
    //    printf("Measured time for total parallel execution = %.3fms\n", total_milliseconds);
    //
    //    cudaMemcpy(D_tree_trans.data(), p_D_tree_d, sizeof(int) * m * n, cudaMemcpyDeviceToHost);
    //    cudaDeviceSynchronize();
    //    printf("D[0][13] = %d, D[61][0] = %d\n", D_tree_trans[0*1000+13], D_tree_trans[61*1000+0]);
    //
    //    vector<vector<int>> final_result(m,vector<int>(n,0));
    //    return final_result;
    //
    //}